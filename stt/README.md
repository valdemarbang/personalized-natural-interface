# Stellar lab installation

Run these commands to be able to run docker in the lab.
```
dockerd-rootless-setuptool.sh install --skip-iptables
export PATH=/usr/bin:$PATH
export DOCKER_HOST=unix:///run/user/10168/docker.sock

to run docker write: 
docker compose up --build

```

# Usage Linux
```
cd stt

python3 -m venv venv

source venv/bin/activate

pip install -r requirements.txt

export PATH="$HOME/.local/bin:$PATH" # Problem which could solve stupid huggingface errors

huggingface-cli download KBLab/kb-whisper-large --loca l-dir src/models/kb-whisper-large --local-dir-use-symlinks False --revision standard

kb_whisper_model.py
```


# Important links
[Whisper Fine-Tuning Event](https://github.com/huggingface/community-events/tree/main/whisper-fine-tuning-event)

Whisper model by default only supports 30 second inference.
With the pipeline object we can auto-magically chunk long audio files and generate reasonably accurate transcriptions.
[Whisper pipeline](https://colab.research.google.com/drive/1l290cRv4RdvuLNlSeo9WexByHaNWs3s3?usp=sharing)

LoRA for less VRAM while fine-tuning the model.
The problem currently is that fine-tuning the Whisper-Large model requires more than 24GB GPU VRAM which the computer in the lab doesnt have.
Thats we why need to fine-tune using LoRA instead.
https://github.com/Vaibhavs10/fast-whisper-finetuning


##  Seq2Seq Parameters
https://huggingface.co/docs/autotrain/seq2seq_params


## Hyperparameter testing
https://medium.com/@chris.xg.wang/a-guide-to-fine-tune-whisper-model-with-hyper-parameter-tuning-c13645ba2dba


## Structure
```
STT
    -output (output from kb-whisper end up here)
    -src (main folder)
        -data_generation (here data is generated by user, audio based on script)
            -recordings (contain audio file, csv file with the text connected to audio.)
                -username (a new folder is created based on the chosen username. contains the data)
        -fine_tuning (Finetuning of the STT model is done here)
            -configs
            -notebook (contains notebooks of the finetuning)

    -old_scripts_audio_backup
```


